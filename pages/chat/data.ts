export const models = [
  "@cf/meta/llama-2-7b-chat-fp16",
  "@cf/mistral/mistral-7b-instruct-v0.1",
  "@cf/meta/llama-2-7b-chat-int8",
  "@cf/mistral/mistral-7b-instruct-v0.1-vllm",
  "@hf/meta-llama/meta-llama-3-8b-instruct",
  "@cf/qwen/qwen1.5-0.5b-chat",
  "@cf/google/gemma-2b-it-lora",
  "@hf/nexusflow/starling-lm-7b-beta",
  "@cf/meta/llama-3-8b-instruct",
  "@hf/thebloke/llamaguard-7b-awq",
  "@hf/thebloke/neural-chat-7b-v3-1-awq",
  "@cf/mistral/mistral-7b-instruct-v0.2-lora",
  "@cf/tinyllama/tinyllama-1.1b-chat-v1.0",
  "@hf/mistral/mistral-7b-instruct-v0.2",
  "@cf/fblgit/una-cybertron-7b-v2-bf16",
  "@cf/thebloke/discolm-german-7b-v1-awq",
  "@hf/thebloke/mistral-7b-instruct-v0.1-awq",
  "@cf/qwen/qwen1.5-7b-chat-awq",
  "@hf/thebloke/llama-2-13b-chat-awq",
  "@hf/thebloke/deepseek-coder-6.7b-base-awq",
  "@cf/meta-llama/llama-2-7b-chat-hf-lora",
  "@hf/thebloke/openhermes-2.5-mistral-7b-awq",
  "@hf/thebloke/deepseek-coder-6.7b-instruct-awq",
  "@cf/deepseek-ai/deepseek-math-7b-instruct",
  "@cf/tiiuae/falcon-7b-instruct",
  "@hf/nousresearch/hermes-2-pro-mistral-7b",
  "@hf/thebloke/zephyr-7b-beta-awq",
  "@cf/google/gemma-7b-it-lora",
  "@cf/qwen/qwen1.5-1.8b-chat",
  "@cf/meta/llama-3-8b-instruct-awq",
  "@cf/defog/sqlcoder-7b-2",
  "@cf/microsoft/phi-2",
  "@hf/google/gemma-7b-it",
  "@cf/qwen/qwen1.5-14b-chat-awq",
  "@cf/openchat/openchat-3.5-0106"
]
